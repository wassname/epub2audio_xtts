{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/miniforge3/envs/tts/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"modified from https://gist.github.com/endes0/0967d7c5bb1877559c4ae84be05e036c\"\"\"\n",
    "from tika import parser\n",
    "\n",
    "import torchaudio\n",
    "import argparse\n",
    "from sanitize_filename import sanitize\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "# import pysbd\n",
    "from typing import List\n",
    "from loguru import logger\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch version does not support flash attention. You will get faster inference speed by upgrade torch to newest nightly version.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/suno-ai/bark/blob/main/notebooks/long_form_generation.ipynb\n",
    "from bark.generation import (\n",
    "    generate_text_semantic,\n",
    "    preload_models,\n",
    ")\n",
    "from bark.api import semantic_to_waveform\n",
    "from bark import generate_audio, SAMPLE_RATE\n",
    "SPEAKER = \"v2/en_speaker_6\"\n",
    "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
    "\n",
    "preload_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Writer:\n",
    "    out_dir: Path\n",
    "    # tts: TTS\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.m3u = open(self.out_dir / 'playlist.m3u', 'w')\n",
    "        self.m3u.write('#EXTM3U\\n')\n",
    "        self.chapter = 1\n",
    "\n",
    "    def write_chapter(self, waveforms: torch.tensor, SAMPLE_RATE=24000):\n",
    "        wav_f = self.out_dir / f'{self.chapter}.ogg'\n",
    "        torchaudio.save(wav_f, waveforms.cpu(), SAMPLE_RATE)\n",
    "        self.m3u.write(f'{wav_f}\\n')\n",
    "        self.chapter += 1\n",
    "        return wav_f\n",
    "\n",
    "    def close(self):\n",
    "        self.m3u.close()\n",
    "\n",
    "def split_into_sentences(text, tokenizer) -> List[str]:        \n",
    "    limit = 200\n",
    "    chunk_limit = limit\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        length_function=lambda x: len(tokenizer.encode(x)),\n",
    "        chunk_size=chunk_limit,\n",
    "        chunk_overlap=0,\n",
    "        keep_separator=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=[\n",
    "            \"\\n\\n\", \"\\n\", \"\\xa0\", '<div>', '<p>', '<br>', \"\\r\", \".\",  \"!\", \"?\", \n",
    "            '\"', \"'\", \"‘\", \"’\", \"“\", \"”\", \"„\", \"‟\",  \n",
    "            \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \n",
    "            \"…\", \":\", \";\", \"—\", \"   \"\n",
    "            \" \", '' # these ensure that there is always something to split by so chunks are always at limit\n",
    "    ],\n",
    "    )\n",
    "    texts = splitter.split_text(text)\n",
    "    ls = [splitter._length_function(x) for x in texts]\n",
    "    logger.debug(f'split lengths {ls}. max={max(ls)} chunk_limit={chunk_limit}')\n",
    "    assert all([l<=limit for l in ls]), 'all senteces should be below limit'\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = '../01_epub_tortise.ipynb'\n",
    "root_dir = Path(__file__).resolve().absolute().parent\n",
    "root_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the command line arguments\n",
    "parser2 = argparse.ArgumentParser()\n",
    "parser2.add_argument('--epub', type=Path, \n",
    "                     default=root_dir/'data/A Short Guide to the Inner Citadel - Massimo Pigliucci.epub',\n",
    "                    #  default=root_dir/'data/golden_saying_of_epictetus.epub',\n",
    "                    help='PDF file to read')\n",
    "parser2.add_argument('-o', '--out', type=Path, default=None, help='Output folder')\n",
    "parser2.add_argument('-t', '--test', action='store_true', default=False, help='Overwrite')\n",
    "parser2.add_argument('-s', '--speaker', type=Path, default=root_dir / \"data/speakers/donaldrobertson.wav\",\n",
    "                    help='Speaker wav to use from the model')\n",
    "args = parser2.parse_args([])\n",
    "\n",
    "if args.out is None:\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.utcnow().strftime('%Y%m%d_%H-%M-%S')\n",
    "    args.out = root_dir / 'out' / (sanitize(args.epub.stem).replace(' ', '_').lower() + '_bark_' + timestamp)\n",
    "\n",
    "# load epib\n",
    "parsed = parser.from_file(str(args.epub))\n",
    "text = parsed[\"content\"]\n",
    "if args.test:\n",
    "    text = text[:1000]\n",
    "\n",
    "# make output directory\n",
    "out_dir = Path(args.out)\n",
    "if out_dir.exists():\n",
    "    if not args.force:\n",
    "        logger.warning('Output folder already exists. Use -f to overwrite.')\n",
    "        exit(1)\n",
    "    else:\n",
    "        for f in out_dir.glob('*'):\n",
    "            f.unlink()\n",
    "        out_dir.rmdir()\n",
    "out_dir.mkdir()\n",
    "logger.info(f'Output folder: {out_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# write metadata to dir\n",
    "from json_tricks import dump, dumps, load, loads, strip_comments\n",
    "f_metadata = out_dir / 'metadata.json'\n",
    "with open(f_metadata, 'w') as fo:\n",
    "    dump(dict(\n",
    "        epub_metadata=parsed['metadata'],\n",
    "        args=args.__dict__,\n",
    "        \n",
    "    ), fo, indent=4)\n",
    "\n",
    "# should be torch tensors containing 22.05kHz waveform data.\n",
    "# see https://github.com/neonbjb/tortoise-tts/blob/5bbb0e0b97ea2f62c12e90402e8ad4faee55e697/tortoise/api.py#L365C82-L365C140\n",
    "ref, INPUT_SAMPLE_RATE = torchaudio.load(args.speaker)\n",
    "reference_clips = [ref[..., -400000:]] # take just the last ~12 seconds\n",
    "\n",
    "# load model\n",
    "use_cuda = False if args.test else torch.cuda.is_available()\n",
    "logger.info(f'use_cuda {use_cuda}')\n",
    "# tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SAMPLE_RATE\n",
    "OUTPUT_SAMPLE_RATE = 24000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global models\n",
    "from bark.generation import models\n",
    "model_container = models[\"text\"]\n",
    "tokenizer = model_container[\"tokenizer\"]\n",
    "tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segs = split_into_sentences(text, tokenizer)\n",
    "waveforms = []\n",
    "writer = Writer(out_dir)\n",
    "for i, t in enumerate(tqdm(segs, desc='chunks')):\n",
    "    t = t.replace('\\n', ' ').strip()\n",
    "    # Skip empty text\n",
    "    if t == None or t == '':\n",
    "        continue\n",
    "    # check if contains words or numbers\n",
    "    if not re.search('[a-zA-Z0-9]', t):\n",
    "        logger.debug(f'Skipping text without words or numbers `{t}`')\n",
    "        continue\n",
    "    logger.debug(f'current sentence `{t}`')\n",
    "    \n",
    "    # wav_t = tts.tts_with_preset(t, voice_samples=reference_clips, preset='fast', verbose=i==0) # ultra_fast, fast, standard\n",
    "    wav_t = generate_audio(t, history_prompt=SPEAKER)\n",
    "    wav = torch.from_numpy(wav_t).unsqueeze(0)\n",
    "    waveforms.append(wav)\n",
    "    \n",
    "    len_wav = sum([w.shape[-1] for w in waveforms])\n",
    "    if len_wav > 10000000//4:  # ~20G of RAM, ~2 minutes of audio output, ~7 minutes to generate\n",
    "        wavs = torch.concat(waveforms, dim=-1).cpu()\n",
    "        wav_f = writer.write_chapter(wavs, OUTPUT_SAMPLE_RATE)\n",
    "        logger.warning(f\"wrote chapter {wav_f}\")\n",
    "       \n",
    "        \n",
    "if len(waveforms):  \n",
    "    wavs = torch.concat(waveforms, dim=-1).cpu()\n",
    "    wav_f = writer.write_chapter(wavs)\n",
    "    logger.warning(f\"wrote chapter {wav_f}\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io.wavfile import write as write_wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Audio\n",
    "# Audio(wav_t, rate=24000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchaudio.save('test.ogg', torch.from_numpy(wav_t).unsqueeze(0), 24000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "# len_wav = sum([w.shape[-1] for w in waveforms])\n",
    "# print(len_wav)\n",
    "\n",
    "# wavs = torch.concat(waveforms, dim=-1).cpu().squeeze(0)\n",
    "# writer.write_chapter(wavs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_folder(folder: Path):\n",
    "    files = sorted(folder.glob('*.ogg'))\n",
    "    tensors = [torchaudio.load(f)[0] for f in files]\n",
    "    tensor = torch.concat(tensors, 1)\n",
    "    f = str(folder) + '.ogg'\n",
    "    torchaudio.save(f, tensor, 24000)\n",
    "    return f\n",
    "    \n",
    "f = join_folder(out_dir)\n",
    "print(f\"saved final file to {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
