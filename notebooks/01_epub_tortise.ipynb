{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassname/miniforge3/envs/tts/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"modified from https://gist.github.com/endes0/0967d7c5bb1877559c4ae84be05e036c\"\"\"\n",
    "from tika import parser\n",
    "\n",
    "import torchaudio\n",
    "import argparse\n",
    "from sanitize_filename import sanitize\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from tortoise.api import TextToSpeech\n",
    "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
    "from tortoise.utils.tokenizer import VoiceBpeTokenizer\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "# import pysbd\n",
    "from typing import List\n",
    "from loguru import logger\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class Writer:\n",
    "    out_dir: Path\n",
    "    # tts: TTS\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.m3u = open(self.out_dir / 'playlist.m3u', 'w')\n",
    "        self.m3u.write('#EXTM3U\\n')\n",
    "        self.chapter = 1\n",
    "\n",
    "    def write_chapter(self, waveforms: torch.tensor, SAMPLE_RATE=22050):\n",
    "        wav_f = self.out_dir / f'{self.chapter}.ogg'\n",
    "        torchaudio.save(wav_f, waveforms.cpu(), SAMPLE_RATE)\n",
    "        self.m3u.write(f'{wav_f}\\n')\n",
    "        self.chapter += 1\n",
    "        return wav_f\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        self.m3u.close()\n",
    "\n",
    "def split_into_sentences(text, tokenizer) -> List[str]:        \n",
    "    limit = 200\n",
    "    chunk_limit = limit\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        length_function=lambda x: len(tokenizer.encode(x)),\n",
    "        chunk_size=chunk_limit,\n",
    "        chunk_overlap=0,\n",
    "        keep_separator=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=[\n",
    "            \"\\n\\n\", \"\\n\", \"\\xa0\", '<div>', '<p>', '<br>', \"\\r\", \".\",  \"!\", \"?\", \n",
    "            '\"', \"'\", \"‘\", \"’\", \"“\", \"”\", \"„\", \"‟\",  \n",
    "            \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \n",
    "            \"…\", \":\", \";\", \"—\", \"   \"\n",
    "            \" \", '' # these ensure that there is always something to split by so chunks are always at limit\n",
    "    ],\n",
    "    )\n",
    "    texts = splitter.split_text(text)\n",
    "    ls = [splitter._length_function(x) for x in texts]\n",
    "    logger.debug(f'split lengths {ls}. max={max(ls)} chunk_limit={chunk_limit}')\n",
    "    assert all([l<=limit for l in ls]), 'all senteces should be below limit'\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/wassname/SGIronWolf/projects5/tts-ai/use-tts-mjc')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__file__ = '../01_epub_tortise.ipynb'\n",
    "root_dir = Path(__file__).resolve().absolute().parent\n",
    "root_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-08 10:32:45.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mOutput folder: /media/wassname/SGIronWolf/projects5/tts-ai/use-tts-mjc/out/golden_saying_of_epictetus20231008_02-32-45\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get the command line arguments\n",
    "parser2 = argparse.ArgumentParser()\n",
    "parser2.add_argument('--epub', type=Path, \n",
    "                    #  default='data/A Short Guide to the Inner Citadel - Massimo Pigliucci.epub',\n",
    "                     default=root_dir/'data/golden_saying_of_epictetus.epub',\n",
    "                    help='PDF file to read')\n",
    "parser2.add_argument('-o', '--out', type=Path, default=None, help='Output folder')\n",
    "parser2.add_argument('-f', '--force', action='store_true', default=False, help='Overwrite')\n",
    "parser2.add_argument('-t', '--test', action='store_true', default=False, help='Overwrite')\n",
    "parser2.add_argument('-l', '--limit', type=int, default=400,\n",
    "                    help='Maximum number of characters to synthesize at once')\n",
    "parser2.add_argument('-m', '--model', type=str, \n",
    "                    default=\"tts_models/multilingual/multi-dataset/xtts_v1\",\n",
    "                    # default='facebook/fastspeech2-en-ljspeech',\n",
    "                    help='fairseq model to use from HuggingFace Hub')\n",
    "parser2.add_argument('-s', '--speaker', type=Path, default=root_dir / \"data/speakers/donaldrobertson.wav\",\n",
    "                    help='Speaker wav to use from the model')\n",
    "args = parser2.parse_args([])\n",
    "\n",
    "if args.out is None:\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.utcnow().strftime('%Y%m%d_%H-%M-%S')\n",
    "    args.out = root_dir / 'out' / (sanitize(args.epub.stem).replace(' ', '_').lower() + timestamp)\n",
    "\n",
    "# load epib\n",
    "parsed = parser.from_file(str(args.epub))\n",
    "text = parsed[\"content\"]\n",
    "if args.test:\n",
    "    text = text[:1000]\n",
    "\n",
    "\n",
    "# make output directory\n",
    "out_dir = Path(args.out)\n",
    "if out_dir.exists():\n",
    "    if not args.force:\n",
    "        logger.warning('Output folder already exists. Use -f to overwrite.')\n",
    "        exit(1)\n",
    "    else:\n",
    "        for f in out_dir.glob('*'):\n",
    "            f.unlink()\n",
    "        out_dir.rmdir()\n",
    "out_dir.mkdir()\n",
    "logger.info(f'Output folder: {out_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-08 10:32:45.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1muse_cuda True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# write metadata to dir\n",
    "from json_tricks import dump, dumps, load, loads, strip_comments\n",
    "f_metadata = out_dir / 'metadata.json'\n",
    "with open(f_metadata, 'w') as fo:\n",
    "    dump(dict(\n",
    "        epub_metadata=parsed['metadata'],\n",
    "        args=args.__dict__,\n",
    "        \n",
    "    ), fo, indent=4)\n",
    "\n",
    "# clips_paths = [args.speaker]\n",
    "ref, SAMPLE_RATE = torchaudio.load(args.speaker)\n",
    "reference_clips = [ref]\n",
    "# None, conditioning_latents = load_voice(voice)\n",
    "# reference_clips+=conditioning_latents\n",
    "\n",
    "# load model\n",
    "use_cuda = False if args.test else torch.cuda.is_available()\n",
    "logger.info(f'use_cuda {use_cuda}')\n",
    "\n",
    "\n",
    "tts = TextToSpeech(use_deepspeed=True, kv_cache=True, half=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = reference_clips[0][..., -400000:]\n",
    "# torchaudio.save(out_dir / 'reference_clip.ogg', w , 22050)\n",
    "# ref, rate = torchaudio.load(args.speaker)\n",
    "# w.shape\n",
    "# 10/(60*5) * 6615000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tts.tokenizer\n",
    "segs = split_into_sentences(text, tokenizer)\n",
    "waveforms = []\n",
    "writer = Writer(out_dir)\n",
    "for i, t in enumerate(tqdm(segs, desc='chunks')):\n",
    "    t = t.replace('\\n', ' ').strip()\n",
    "    # Skip empty text\n",
    "    if t == None or t == '':\n",
    "        continue\n",
    "    # check if contains words or numbers\n",
    "    if not re.search('[a-zA-Z0-9]', t):\n",
    "        logger.debug(f'Skipping text without words or numbers `{t}`')\n",
    "        continue\n",
    "    logger.debug(f'current sentence `{t}`')\n",
    "    \n",
    "    wav_t = tts.tts_with_preset(t, voice_samples=reference_clips, preset='fast') # ultra_fast, fast, standard\n",
    "    wav = wav_t.cpu()\n",
    "    waveforms.append(wav)\n",
    "    \n",
    "    len_wav = sum([w.shape[-1] for w in waveforms])\n",
    "    if len_wav > 10000000//4:  # ~20G\n",
    "        # wav_f = out_dir / f'{i}.wav'\n",
    "        wavs = torch.concat(waveforms, dim=-1).cpu()\n",
    "        wav_f = writer.write_chapter(wavs, SAMPLE_RATE)\n",
    "        logger.warning(f\"wrote chapter {wav_f}\")\n",
    "        waveforms = []\n",
    "        \n",
    "if len(waveforms):  \n",
    "    writer.write_chapter(waveforms)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "len_wav = sum([w.shape[-1] for w in waveforms])\n",
    "print(len_wav)\n",
    "\n",
    "wavs = torch.concat(waveforms, dim=-1).cpu().squeeze(0)\n",
    "writer.write_chapter(wavs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
